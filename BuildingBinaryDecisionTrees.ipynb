{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building a Binary Decision Tree from Data**\n",
    "\n",
    "Suppose we have a dataset with some predictor variables $x_1,x_2,\\ldots,x_k$ and binary response variable $Y.$ For example, for the mortgage dataset we have predictors (location, principal, interest rate, credit score) and we want to predict the result (default, non-default). Our datset is _flat_/_rectangular_, with N rows and $k+1$ columns, with one column for each variable and one row for each _observation_ (mortgage loan).\n",
    "\n",
    "We wish to use these data to build a decision tree in which the functions at the nodes are functions of the the predictor variables. \n",
    "\n",
    "Assume $Y$ takes the value 0 or 1. \n",
    "\n",
    "The predictor variables can be categorical or continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recursive Description of the Algorithm**\n",
    "\n",
    "The algorithm for building the tree has a recursive definition.\n",
    "\n",
    "We begin by creating a root node with the entire dataset as attached to that node.\n",
    "\n",
    "We start at the root node.\n",
    "\n",
    "Whenever we visit a node, we compute and store at the node the following information about the dataset attached to the node:\n",
    "\n",
    "a) the number of observations in the dataset attached to that node, and \n",
    "\n",
    "b) the proportion of observations in each class (Y=0 or 1)\n",
    "\n",
    "Next, we take one of the following actions:\n",
    "\n",
    "1) Find a function (splitting function) that splits/partitions the data into two pieces. The two pieces should look different in the sense that one piece tends to have a different proportions of observations with Y=1, and the pieces are each sufficiently large. Call these pieces left piece and right piece. If such a _split_ can be found, we attach the splitting function to the node, spawn two children of the current node, attach piece \\#1 to the left child  and piece \\#2 to the right child, and visit each of those children. \n",
    "\n",
    "or\n",
    "\n",
    "2) Determine that a splitting function cannot be found so the current node becomes a leaf node (no children). \n",
    "\n",
    "The splitting function should be a function of $x_1,x_2,...,x_k$ that returns a value of \"left\" or \"right\". Typically, this function is taken to be a function of only one of the $x_i$'s and \n",
    "\n",
    "a) for a continuous variable this is a function of the form:  if $xi < c$ return(\"left\") else return(\"right)\n",
    "\n",
    "b) for a categorical variable, this function takes the form: if $x \\in I$ return(\"left\") else return(\"right\") where $I$ is a subset of the values that the variable can take."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to Classify/Predict $Y$ for a New Observation**\n",
    "\n",
    "Given a new observation with predictor variables $x1,x2,\\ldots,xk$ we start at the root node and for each node we visit, we do one of the following:\n",
    "\n",
    "a) if the node has chilren, apply the splitting function at the current node to determine which child node to visit next, or\n",
    "\n",
    "b) if the current node is a leaf node, return the proportion $p_1$ of observations with $Y=1$ at that node\n",
    "\n",
    "Finally, we predict $Y=1$ if $p_1$ exceeds some pre-determined threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting Criterion - how to find a good splitting function**\n",
    "\n",
    "We need a criterion for deciding on a good splitting function. There are several possibilities. We focus here on the Gini index.\n",
    "\n",
    "Given a categorical variable taking K possible values and a set of data for that variable with proportions $p_1,p_2,\\ldots,p_K$ of values in each category we define the Gini index by\n",
    "\n",
    "$$ G = \\sum_{i=1}^k p_i(1-p_i)$$\n",
    "\n",
    "This number has the following interpretation. If we pick a data point at random, and classify it as class 1 with probability $p_1,$ class 2 with probability $p_2,$ etc., $G$ is the probability of incorrectly classifying that observation.\n",
    "\n",
    "$G$ is a measure of _impurity_ of the dataset with regard to the class variable, if one of the $p_i$ is one and the others are zero (perfect _purity_) we get $G=0.$ In in the case of a binary class variable, with $p_1=p_2=1/2$ we get $G =1/2.$ \n",
    "\n",
    "When we split out dataset into two pieces, we would like the two child datasets to be as pure as possible so we try to minimize the quantity\n",
    "\n",
    "$$ N_{left} G_{left} + N_{right} G_{right}$$\n",
    "\n",
    "that is, the weighted sum of the impurities of the child datasets weighted by the number of observations in the datasets.\n",
    "\n",
    "It is typical to require for splitting that the size of each child dataaet be above some pre-determined threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>princ</th>\n",
       "      <th>irate</th>\n",
       "      <th>cscore</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>suburban</td>\n",
       "      <td>358</td>\n",
       "      <td>7.00</td>\n",
       "      <td>728</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>suburban</td>\n",
       "      <td>637</td>\n",
       "      <td>7.25</td>\n",
       "      <td>675</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>suburban</td>\n",
       "      <td>303</td>\n",
       "      <td>7.25</td>\n",
       "      <td>645</td>\n",
       "      <td>non-default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>suburban</td>\n",
       "      <td>397</td>\n",
       "      <td>7.25</td>\n",
       "      <td>609</td>\n",
       "      <td>non-default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>suburban</td>\n",
       "      <td>420</td>\n",
       "      <td>7.75</td>\n",
       "      <td>669</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   location  princ  irate  cscore       result\n",
       "0  suburban    358   7.00     728      default\n",
       "1  suburban    637   7.25     675      default\n",
       "2  suburban    303   7.25     645  non-default\n",
       "3  suburban    397   7.25     609  non-default\n",
       "4  suburban    420   7.75     669      default"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "mdata=pd.read_csv(\"mortgage_data.csv\")\n",
    "print(type(mdata))\n",
    "mdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>princ</th>\n",
       "      <th>irate</th>\n",
       "      <th>cscore</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9859</th>\n",
       "      <td>suburban</td>\n",
       "      <td>769</td>\n",
       "      <td>7.75</td>\n",
       "      <td>586</td>\n",
       "      <td>non-default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9860</th>\n",
       "      <td>suburban</td>\n",
       "      <td>451</td>\n",
       "      <td>7.25</td>\n",
       "      <td>684</td>\n",
       "      <td>non-default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9861</th>\n",
       "      <td>suburban</td>\n",
       "      <td>410</td>\n",
       "      <td>7.00</td>\n",
       "      <td>702</td>\n",
       "      <td>non-default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9862</th>\n",
       "      <td>suburban</td>\n",
       "      <td>851</td>\n",
       "      <td>7.00</td>\n",
       "      <td>774</td>\n",
       "      <td>non-default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9863</th>\n",
       "      <td>suburban</td>\n",
       "      <td>260</td>\n",
       "      <td>7.50</td>\n",
       "      <td>657</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      location  princ  irate  cscore       result\n",
       "9859  suburban    769   7.75     586  non-default\n",
       "9860  suburban    451   7.25     684  non-default\n",
       "9861  suburban    410   7.00     702  non-default\n",
       "9862  suburban    851   7.00     774  non-default\n",
       "9863  suburban    260   7.50     657      default"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdata.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9864, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create a Y variable - Y=1 for default Y=0 for non-default\n",
    "#\n",
    "def f(row):\n",
    "    if row[\"result\"]==\"default\":\n",
    "        return(1)\n",
    "    else:\n",
    "        return(0)\n",
    "mdata[\"Y\"]=mdata.apply(f,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdata[\"Y\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>princ</th>\n",
       "      <th>irate</th>\n",
       "      <th>cscore</th>\n",
       "      <th>result</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>suburban</td>\n",
       "      <td>358</td>\n",
       "      <td>7.00</td>\n",
       "      <td>728</td>\n",
       "      <td>default</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>suburban</td>\n",
       "      <td>637</td>\n",
       "      <td>7.25</td>\n",
       "      <td>675</td>\n",
       "      <td>default</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>suburban</td>\n",
       "      <td>303</td>\n",
       "      <td>7.25</td>\n",
       "      <td>645</td>\n",
       "      <td>non-default</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>suburban</td>\n",
       "      <td>397</td>\n",
       "      <td>7.25</td>\n",
       "      <td>609</td>\n",
       "      <td>non-default</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>suburban</td>\n",
       "      <td>420</td>\n",
       "      <td>7.75</td>\n",
       "      <td>669</td>\n",
       "      <td>default</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   location  princ  irate  cscore       result  Y\n",
       "0  suburban    358   7.00     728      default  1\n",
       "1  suburban    637   7.25     675      default  1\n",
       "2  suburban    303   7.25     645  non-default  0\n",
       "3  suburban    397   7.25     609  non-default  0\n",
       "4  suburban    420   7.75     669      default  1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "suburban    5347\n",
       "urban       2423\n",
       "rural       2094\n",
       "Name: location, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdata[\"location\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate quality of a split**\n",
    "\n",
    "Let's write code to evaluate quality of an example of a splitting function.\n",
    "\n",
    "That code should take a pandas data frame and a function as arguments.\n",
    "\n",
    "If a split would produce nodes with sizes below some threshold, we return a value so large that it can't reduce Gini coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of a splitting function**\n",
    "\n",
    "Here, we classify a row (an observation) according to whether the **cscore** for that row exceeds some threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(row):\n",
    "    if row[\"cscore\"]>620:\n",
    "        return(\"left\")\n",
    "    else:\n",
    "        return(\"right\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gini criterion**\n",
    "\n",
    "The following function takes as an argument a function, a data frame, and a minimum node size, and calculates the Gini criterion.\n",
    "\n",
    "If splitting produces a node that has too few observations (less than min_node_size) we return a large value so that we'll not choose this splitting function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gini_criterion(df,f,min_node_size):\n",
    "    #\n",
    "    # calculate f(row) for every row in the data frame\n",
    "    # this produces a Pandas series\n",
    "    #\n",
    "    fvalue=df.apply(f,axis=1)\n",
    "    #\n",
    "    # get the series of Y's for which fvalue is \"left\" \n",
    "    # and the series of Y's for whcih fvalue is \"right\"\n",
    "    #\n",
    "    Yleft=df[\"Y\"].loc[fvalue==\"left\"]\n",
    "    Yright=df[\"Y\"].loc[fvalue==\"right\"]\n",
    "    #\n",
    "    # compute number of obs in each side\n",
    "    #\n",
    "    nleft=Yleft.size\n",
    "    nright=Yright.size\n",
    "    #\n",
    "    # if split puts too few values in a node\n",
    "    # we return a value that makes it so we'd never choose this f\n",
    "    #\n",
    "    if nleft<min_node_size or nright<min_node_size:\n",
    "        return(nleft+nright)\n",
    "    \n",
    "    p1left=Yleft.loc[Yleft==1].size/nleft\n",
    "    p1right=Yright.loc[Yright==1].size/nright\n",
    "    #\n",
    "    # compute the Gini coefficient\n",
    "    #\n",
    "    Gini=Yleft.size*p1left*(1-p1left)+Yright.size*p1right*(1-p1right)\n",
    "    return(Gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ginivalue=Gini_criterion(mdata,f,100)\n",
    "print(ginivalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Another example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(row):\n",
    "    if row[\"irate\"]>7:\n",
    "        return(\"left\")\n",
    "    else:\n",
    "        return(\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ginivalue=Gini_criterion(mdata,f,100)\n",
    "print(ginivalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal**\n",
    "\n",
    "We want our children to be as pure as possible, and we see that Gini impurity is lower for this splitting function than the one above, so this one would be preferred. We can ask for the best possible split based on a continuous variable or a categorical variable.\n",
    "\n",
    "For a continuous variable v we could try every possible split of the form: $v<c$ vs. $v>c$ but that might take too long to compute. Instead we try only using some quantiles  for that variable. Below, quartiles are used, but there are other options, e.g. deciles, percentiles.\n",
    "\n",
    "If a split would produce a node with too few values, we return a huge gini value (one that can't be smaller than the current one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_splitting_function_continuous_variable(data,vname,min_node_size):\n",
    "    # to use e.g. deciles we change the two 4's here to 10's\n",
    "    qvalues=[data[vname].quantile(i/4) for i in range(1,4)]\n",
    "    minginivalue=mdata.shape[0] # Gini can't be this big\n",
    "    for qvalue in qvalues:\n",
    "        def f(row):\n",
    "            if row[vname]<qvalue:\n",
    "                return(\"left\")\n",
    "            else:\n",
    "                return(\"right\")\n",
    "        ginivalue=Gini_criterion(data,f,min_node_size)\n",
    "        if ginivalue<minginivalue:\n",
    "            bestf=f\n",
    "            bestvalue=qvalue\n",
    "            minginivalue=ginivalue\n",
    "    #\n",
    "    # return the best function, the value and its gini value\n",
    "    #\n",
    "    return(bestf,bestvalue,minginivalue)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,v,g=find_best_splitting_function_continuous_variable(mdata,\"cscore\",100)\n",
    "print(v)\n",
    "print(g)\n",
    "f,v,g=find_best_splitting_function_continuous_variable(mdata,\"irate\",100)\n",
    "print(v)\n",
    "print(g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splits for a categorical variable**\n",
    "\n",
    "We need a function to try all splits of a categorical variable v taking values in a set say S={1,2,3,...,K}\n",
    "\n",
    "Here we try splitting on a given subset T of S -sending those observations with values of v in T to the left and the others to the right.\n",
    "\n",
    "We can then iterate over all nonempty subsets T to find the minimizer of the Gini criterion - Note that this code is less than optimal because every set is tested twice - once when we send observations with values in T to the left and again when we send all observations in the complement of T to the left.\n",
    "\n",
    "The itertools package is handy for getting all combinations of elements in a list of some size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "L=list(it.combinations([1,2,3],2))\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting all subsets**\n",
    "\n",
    "We need a list of all ways we can split a list of values into two nonempty pieces. This is straightforward if n, the size of the list is odd, we just need to make a list of all subsets of size 1,2,...,(n-1)/2. But if n is even we don't want to check each split of a subset of size n/2 twice (once for the subset and once for its complement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_set_splits(value_list):\n",
    "    splits=[]\n",
    "    n=len(value_list)\n",
    "    m=int(n/2)\n",
    "    for sz in range(1,m+1):\n",
    "        combs=it.combinations(value_list,sz)\n",
    "        for comb in combs:\n",
    "            splits.append(list(comb))\n",
    "    if 2*m<n:\n",
    "        return(splits)\n",
    "    #\n",
    "    # even case - need to add in subsets of size n/2\n",
    "    #\n",
    "    combs=it.combinations(value_list,m+1)\n",
    "    svalue_list=set(value_list) # by the way - sets can't contain mutable elements!!!\n",
    "    for comb in combs:\n",
    "        s=set(comb)\n",
    "        sc=svalue_list.difference(s)\n",
    "        if s not in splits and svalue_list.difference(s):\n",
    "            splits.append(list(s))\n",
    "    return(splits)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_all_set_splits(['dog',\"cat\",\"bird\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_all_set_splits([\"dog\",\"cat\",\"bird\",\"turtle\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_splitting_function_categorical_variable(data,vname,min_node_size):\n",
    "    values=list(data[vname].unique())\n",
    "    nvalues=len(values)\n",
    "    minginivalue=data.shape[0] # Gini can't be this big\n",
    "    subset_list=find_all_set_splits(values)\n",
    "    for subset in subset_list:\n",
    "        def f(row):\n",
    "            if row[vname] in subset:\n",
    "                return(\"left\")\n",
    "            else:\n",
    "                return(\"right\")\n",
    "        ginivalue=Gini_criterion(data,f,min_node_size)\n",
    "        if ginivalue<minginivalue:\n",
    "            bestf=f\n",
    "            bestsubset=subset\n",
    "            minginivalue=ginivalue\n",
    "    return(bestf,bestsubset,minginivalue)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_splitting_function_categorical_variable(mdata,\"location\",100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding best split using all variables (continuous & categorical)**\n",
    "\n",
    "Now we can try all continuous *and* categorical variables looking for the best split.\n",
    "\n",
    "The following function takes a data set, a list of continuous variables, and a list of categorical variables as input and finds the best function to split the data on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(data,cont_vars,cat_vars,min_node_size):\n",
    "    minginivalue=data.shape[0]\n",
    "    for catvar in cat_vars:\n",
    "        f,b,g=find_best_splitting_function_categorical_variable(data,catvar,min_node_size)\n",
    "        if g<minginivalue:\n",
    "            minginivalue=g\n",
    "            bestvar=catvar\n",
    "            bestvartype=\"categorical\"\n",
    "            bestvalue=b\n",
    "            bestf=f\n",
    "    for contvar in cont_vars:\n",
    "        f,b,g=find_best_splitting_function_continuous_variable(data,contvar,min_node_size)\n",
    "        if g<minginivalue:\n",
    "            minginivalue=g\n",
    "            bestvar=contvar\n",
    "            bestvartype=\"continuous\"\n",
    "            bestvalue=b\n",
    "            bestf=f\n",
    "    return bestf,bestvar,bestvartype,bestvalue,minginivalue\n",
    "find_best_split(mdata,[\"irate\",\"cscore\",\"princ\"],[\"location\"],100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Build tree recursively*\n",
    "\n",
    "We need a function that builds a tree by starting at root and recursively splitting each node until a stopping rule kicks in.\n",
    "\n",
    "To keep things simple, we'll stop splitting if a node has fewer than 25 observations.\n",
    "\n",
    "Each time we split, we attach a data frame data[\"df\"] to each new node.\n",
    "\n",
    "As we go along, we'll attach the counts of Y=0 and Y=1 to each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "def Gini_criterion(df,f,min_node_size):\n",
    "    #\n",
    "    # calculate f(row) for every row in the data frame\n",
    "    # this produces a Pandas series\n",
    "    #\n",
    "    fvalue=df.apply(f,axis=1)\n",
    "    #\n",
    "    # get the series of Y's for which fvalue is \"left\" \n",
    "    # and the series of Y's for whcih fvalue is \"right\"\n",
    "    #\n",
    "    Yleft=df[\"Y\"].loc[fvalue==\"left\"]\n",
    "    Yright=df[\"Y\"].loc[fvalue==\"right\"]\n",
    "    #\n",
    "    # compute number of obs in each side\n",
    "    #\n",
    "    nleft=Yleft.size\n",
    "    nright=Yright.size\n",
    "    #\n",
    "    # if split puts too few values in a node\n",
    "    # we return a value that makes it so we'd never choose this f\n",
    "    #\n",
    "    if nleft<min_node_size or nright<min_node_size:\n",
    "        return(nleft+nright)\n",
    "    \n",
    "    p1left=Yleft.loc[Yleft==1].size/nleft\n",
    "    p1right=Yright.loc[Yright==1].size/nright\n",
    "    #\n",
    "    # compute the Gini coefficient\n",
    "    #\n",
    "    Gini=Yleft.size*p1left*(1-p1left)+Yright.size*p1right*(1-p1right)\n",
    "    return(Gini)\n",
    "def find_best_splitting_function_continuous_variable(data,vname,min_node_size):\n",
    "    qvalues=[data[vname].quantile(i/4) for i in range(1,4)]\n",
    "    minginivalue=mdata.shape[0] # Gini can't be this big\n",
    "    bestf=None\n",
    "    bestvalue=None\n",
    "    for qvalue in qvalues:\n",
    "        def f(row):\n",
    "            if row[vname]<qvalue:\n",
    "                return(\"left\")\n",
    "            else:\n",
    "                return(\"right\")\n",
    "        ginivalue=Gini_criterion(data,f,min_node_size)\n",
    "        if ginivalue<minginivalue:\n",
    "            bestf=f\n",
    "            bestvalue=qvalue\n",
    "            minginivalue=ginivalue\n",
    "    #\n",
    "    # return the best function, the value and its gini value\n",
    "    #\n",
    "    return(bestf,bestvalue,minginivalue)  \n",
    "\n",
    "\n",
    "def find_all_set_splits(value_list):\n",
    "    splits=[]\n",
    "    n=len(value_list)\n",
    "    m=int(n/2)\n",
    "    for sz in range(1,m+1):\n",
    "        combs=it.combinations(value_list,sz)\n",
    "        for comb in combs:\n",
    "            splits.append(list(comb))\n",
    "    if 2*m<n:\n",
    "        return(splits)\n",
    "    #\n",
    "    # even case - need to add in subsets of size n/2\n",
    "    #\n",
    "    combs=it.combinations(value_list,m+1)\n",
    "    svalue_list=set(value_list) # by the way - sets can't contain mutable elements!!!\n",
    "    for comb in combs:\n",
    "        s=set(comb)\n",
    "        sc=svalue_list.difference(s)\n",
    "        if s not in splits and svalue_list.difference(s):\n",
    "            splits.append(list(s))\n",
    "    return(splits)\n",
    "    \n",
    "def find_best_splitting_function_categorical_variable(data,vname,min_node_size):\n",
    "    values=list(data[vname].unique())\n",
    "    nvalues=len(values)\n",
    "    minginivalue=data.shape[0] # Gini can't be this big\n",
    "    subset_list=find_all_set_splits(values)\n",
    "    bestf=None\n",
    "    bestsubset=None\n",
    "    for subset in subset_list:\n",
    "        def f(row):\n",
    "            if row[vname] in subset:\n",
    "                return(\"left\")\n",
    "            else:\n",
    "                return(\"right\")\n",
    "        ginivalue=Gini_criterion(data,f,min_node_size)\n",
    "        if ginivalue<minginivalue:\n",
    "            bestf=f\n",
    "            bestsubset=subset\n",
    "            minginivalue=ginivalue\n",
    "    return(bestf,bestsubset,minginivalue)  \n",
    "\n",
    "def find_best_split(data,cont_vars,cat_vars,min_node_size):\n",
    "    minginivalue=data.shape[0]\n",
    "    bestf=None\n",
    "    bestvar=None\n",
    "    bestvartype=None\n",
    "    bestvalue=None\n",
    "    for catvar in cat_vars:\n",
    "        f,b,g=find_best_splitting_function_categorical_variable(data,catvar,min_node_size)\n",
    "        if g<minginivalue:\n",
    "            minginivalue=g\n",
    "            bestvar=catvar\n",
    "            bestvartype=\"categorical\"\n",
    "            bestvalue=b\n",
    "            bestf=f\n",
    "    for contvar in cont_vars:\n",
    "        f,b,g=find_best_splitting_function_continuous_variable(data,contvar,min_node_size)\n",
    "        if g<minginivalue:\n",
    "            minginivalue=g\n",
    "            bestvar=contvar\n",
    "            bestvartype=\"continuous\"\n",
    "            bestvalue=b\n",
    "            bestf=f\n",
    "    return bestf,bestvar,bestvartype,bestvalue,minginivalue\n",
    "\n",
    "class node:\n",
    "    __slots__=('parent','left_child','right_child','data')\n",
    "    #\n",
    "    # We instantiate a node by passing a parent (which can be None) \n",
    "    # and a dictionary\n",
    "    #\n",
    "    def __init__(self,parent,data):\n",
    "        if parent==None:\n",
    "            # making this a root node\n",
    "            self.data=data\n",
    "            self.data[\"depth\"]=0\n",
    "            self.parent=None\n",
    "        else:\n",
    "            # making this a non-root node\n",
    "            self.data=data\n",
    "            self.data[\"depth\"]=parent.data[\"depth\"]+1\n",
    "            self.parent=parent\n",
    "        self.left_child=None\n",
    "        self.right_child=None\n",
    "    def get_parent(self): # return the node's parent\n",
    "        return(self.parent)\n",
    "    def get_data(self):   # return the node's data\n",
    "        return(self.data)\n",
    "    def get_depth(self):  # return the node's depth\n",
    "        return(self.data[\"depth\"])\n",
    "    def get_label(self):\n",
    "        return(self.data[\"label\"])\n",
    "    def set_label(self,label):\n",
    "        self.data[\"label\"]=label\n",
    "    def get_left_child(self):\n",
    "        return(self.left_child)\n",
    "    def get_right_child(self):\n",
    "        return(self.right_child)\n",
    "    def spawn_left_child(self,data):\n",
    "        # create a new node n with self as parent w/ given data\n",
    "        n=node(parent=self,data=data)\n",
    "        #n.data=data\n",
    "        n.data[\"depth\"]=self.data[\"depth\"]+1\n",
    "        self.left_child=n\n",
    "        return(n)\n",
    "    def spawn_right_child(self,data):\n",
    "        n=node(parent=self,data=data)\n",
    "        n.data=data\n",
    "        n.data[\"depth\"]=self.data[\"depth\"]+1\n",
    "        self.right_child=n\n",
    "        return(n)\n",
    "    #\n",
    "    # string consisting of information about node\n",
    "    #\n",
    "    def __str__(self):\n",
    "        s=\"node label = \"+self.data[\"label\"]+\"\\n\"\n",
    "        if self.parent==None:\n",
    "            s+=\"   no parent i.e. root node\\n\"\n",
    "        else:\n",
    "            s+=\"   parent label = \" + self.parent.data[\"label\"]+\"\\n\"\n",
    "        if self.left_child==None:\n",
    "            s+=\"   no left child\\n\"\n",
    "        else:\n",
    "            s+=\"   left child label \" + self.left_child.data[\"label\"]+\"\\n\"\n",
    "        if self.right_child==None:\n",
    "            s+=\"   no right child\\n\"\n",
    "        else:\n",
    "            s+=\"   right child label \" + self.right_child.data[\"label\"]+\"\\n\"\n",
    "        return(s)\n",
    "    def treestr(self):\n",
    "        d=self.data\n",
    "        depth=d[\"depth\"]\n",
    "        G=d[\"gini\"]\n",
    "        Gstring=\"G: {:8.2f} \".format(G)\n",
    "        Y0=d[\"Ycts\"][0]\n",
    "        Y1=d[\"Ycts\"][1]\n",
    "        Ycts_string=\"N: \"+str(Y0+Y1)+\" N0: \"+str(Y0)+\" \"+\" N1:\"+str(Y1)+\"\\n\"\n",
    "        p0=Y0/(Y0+Y1)\n",
    "        p1=Y1/(Y0+Y1)\n",
    "        pstring=\"p0: {:5.4f} p1: {:5.4f}\\n\".format(p0,p1)\n",
    "        spaces=\"\".join([\"  \" for i in range(depth)])\n",
    "        s=spaces+d[\"label\"]+\"\\n\"\n",
    "        s+=spaces+Gstring+Ycts_string\n",
    "        s+=spaces+pstring\n",
    "        #\n",
    "        # if this node has a split, include info about it\n",
    "        #\n",
    "        if \"splitinfo\" in self.data:\n",
    "            splitinfo=self.data[\"splitinfo\"]\n",
    "        \n",
    "        \n",
    "        \n",
    "        if self.left_child!=None:\n",
    "            s+=self.left_child.treestr()\n",
    "            s+=self.right_child.treestr()\n",
    "        return(s)\n",
    "    def treeprint(self):\n",
    "        s=self.treestr()\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recursive split node function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new node to try splitting:  size= 9864\n",
      "splitting node into sizes 6781 3083\n",
      "new node to try splitting: L size= 6781\n",
      "splitting node into sizes 2981 3800\n",
      "new node to try splitting: LL size= 2981\n",
      "splitting node into sizes 627 2354\n",
      "new node to try splitting: LLL size= 627\n",
      "node is not split since gini not reduced\n",
      "new node to try splitting: LLR size= 2354\n",
      "splitting node into sizes 637 1717\n",
      "new node to try splitting: LLRL size= 637\n",
      "node is not split since gini not reduced\n",
      "new node to try splitting: LLRR size= 1717\n",
      "node is not split because of minimum node size constraint\n",
      "new node to try splitting: LR size= 3800\n",
      "splitting node into sizes 2850 950\n",
      "new node to try splitting: LRL size= 2850\n",
      "splitting node into sizes 2133 717\n",
      "new node to try splitting: LRLL size= 2133\n",
      "splitting node into sizes 661 1472\n",
      "new node to try splitting: LRLLL size= 661\n",
      "node is not split since gini not reduced\n",
      "new node to try splitting: LRLLR size= 1472\n",
      "node is not split because of minimum node size constraint\n",
      "new node to try splitting: LRLR size= 717\n",
      "node is not split since gini not reduced\n",
      "new node to try splitting: LRR size= 950\n",
      "node is not split since gini not reduced\n",
      "new node to try splitting: R size= 3083\n",
      "splitting node into sizes 636 2447\n",
      "new node to try splitting: RL size= 636\n",
      "node is not split since gini not reduced\n",
      "new node to try splitting: RR size= 2447\n",
      "splitting node into sizes 786 1661\n",
      "new node to try splitting: RRL size= 786\n",
      "node is not split since gini not reduced\n",
      "new node to try splitting: RRR size= 1661\n",
      "splitting node into sizes 863 798\n",
      "new node to try splitting: RRRL size= 863\n",
      "node is not split since gini not reduced\n",
      "new node to try splitting: RRRR size= 798\n",
      "node is not split since gini not reduced\n"
     ]
    }
   ],
   "source": [
    "def split_node(cnode,contvars,catvars,min_node_size):  \n",
    "    cdf=cnode.data[\"df\"]\n",
    "    \n",
    "    # compute Y counts in this node and store them\n",
    "    N0=np.sum(1-cdf[\"Y\"])\n",
    "    N1=np.sum(cdf[\"Y\"])\n",
    "    cnode.data[\"Ycts\"]=[N0,N1]\n",
    "    \n",
    "    #\n",
    "    # Gini for a node is N*p(1-p) where p is prop of 1's\n",
    "    # so this equalis (N0+N1)*(N0/(N0+N1)))*(N1/(N0+N1)) = N0*N1/(N0+N1)\n",
    "    #\n",
    "    cnode.data[\"gini\"]=N0*N1/(N0+N1)\n",
    "    \n",
    "    if cnode.data[\"df\"].shape[0]>=min_node_size:\n",
    "        print(\"new node to try splitting: \"+cnode.data[\"label\"]+\" size= \"+str(cnode.data[\"df\"].shape[0]))\n",
    "        \n",
    "        # find best split\n",
    "        f,v,vtype,value,g=find_best_split(cnode.data[\"df\"],contvars,catvars,min_node_size)\n",
    "        \n",
    "        #\n",
    "        # if the split leads to a bigger gini, we don't split the node\n",
    "        # so compare to gini at current node\n",
    "        #\n",
    "        if g>=cnode.data[\"gini\"]:\n",
    "            print(\"node is not split since gini not reduced\")\n",
    "        else:\n",
    "            \n",
    "            # determine which rows of current data frame go left and which go right\n",
    "            child_assignment=cnode.data[\"df\"].apply(f,axis=1)\n",
    "        \n",
    "            # compute counts of child nodes if we split\n",
    "            nleft=np.sum(child_assignment==\"left\")\n",
    "            nright=np.sum(child_assignment==\"right\")\n",
    "            \n",
    "            if nleft<min_node_size or nright<min_node_size:\n",
    "                print(\"node is not split because of minimum node size constraint\")\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                # attach splitting function to data at this node\n",
    "                splitinfo={\"f\":f, \"vname\": v, \"vtype\":vtype, \"value\":value}\n",
    "                cnode.data[\"splitinfo\"]=splitinfo\n",
    "                     \n",
    "                print(\"splitting node into sizes \"+str(nleft)+\" \"+str(nright))\n",
    "                # compute data frames to put at child nodes\n",
    "                dfleft=cnode.data[\"df\"].loc[child_assignment==\"left\"].copy()\n",
    "                dfright=cnode.data[\"df\"].loc[child_assignment==\"right\"].copy()\n",
    "       \n",
    "                # replace data frame indices by range\n",
    "                dfleft.index=range(dfleft.shape[0])\n",
    "                dfright.index=range(dfright.shape[0])\n",
    "    \n",
    "                # create a label \n",
    "                dataleft={\"df\":dfleft,\"label\":cnode.data[\"label\"]+\"L\"}\n",
    "                dataright={\"df\":dfright,\"label\":cnode.data[\"label\"]+\"R\"}\n",
    "                        \n",
    "                # create child nodes \n",
    "                left_child=cnode.spawn_left_child(dataleft)\n",
    "                right_child=cnode.spawn_right_child(dataright)\n",
    "               \n",
    "            \n",
    "                # split child nodes\n",
    "                split_node(left_child,contvars,catvars,min_node_size)\n",
    "                split_node(right_child,contvars,catvars,min_node_size)\n",
    "\n",
    "mdata=pd.read_csv(\"mortgage_data.csv\")\n",
    "#\n",
    "# Create a Y variable - Y=1 for default Y=0 for non-default\n",
    "#\n",
    "def f(row):\n",
    "    if row[\"result\"]==\"default\":\n",
    "        return(1)\n",
    "    else:\n",
    "        return(0)\n",
    "mdata[\"Y\"]=mdata.apply(f,axis=1)\n",
    "rootnode=node(None,{\"df\":mdata,\"label\":\"\"})\n",
    "split_node(rootnode,[\"irate\",\"cscore\",\"princ\"],[\"location\"],500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootnode.treeprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make the split node function a class method**\n",
    "\n",
    "That function has been renamed to build_tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "def Gini_criterion(df,f,min_node_size):\n",
    "    #\n",
    "    # calculate f(row) for every row in the data frame\n",
    "    # this produces a Pandas series\n",
    "    #\n",
    "    fvalue=df.apply(f,axis=1)\n",
    "    #\n",
    "    # get the series of Y's for which fvalue is \"left\" \n",
    "    # and the series of Y's for whcih fvalue is \"right\"\n",
    "    #\n",
    "    Yleft=df[\"Y\"].loc[fvalue==\"left\"]\n",
    "    Yright=df[\"Y\"].loc[fvalue==\"right\"]\n",
    "    #\n",
    "    # compute number of obs in each side\n",
    "    #\n",
    "    nleft=Yleft.size\n",
    "    nright=Yright.size\n",
    "    #\n",
    "    # if split puts too few values in a node\n",
    "    # we return a value that makes it so we'd never choose this f\n",
    "    #\n",
    "    if nleft<min_node_size or nright<min_node_size:\n",
    "        return(nleft+nright)\n",
    "    \n",
    "    p1left=Yleft.loc[Yleft==1].size/nleft\n",
    "    p1right=Yright.loc[Yright==1].size/nright\n",
    "    #\n",
    "    # compute the Gini coefficient\n",
    "    #\n",
    "    Gini=Yleft.size*p1left*(1-p1left)+Yright.size*p1right*(1-p1right)\n",
    "    return(Gini)\n",
    "def find_best_splitting_function_continuous_variable(data,vname,min_node_size):\n",
    "    qvalues=[data[vname].quantile(i/4) for i in range(1,4)]\n",
    "    minginivalue=mdata.shape[0] # Gini can't be this big\n",
    "    bestf=None\n",
    "    bestvalue=None\n",
    "    for qvalue in qvalues:\n",
    "        def f(row):\n",
    "            if row[vname]<qvalue:\n",
    "                return(\"left\")\n",
    "            else:\n",
    "                return(\"right\")\n",
    "        ginivalue=Gini_criterion(data,f,min_node_size)\n",
    "        if ginivalue<minginivalue:\n",
    "            bestf=f\n",
    "            bestvalue=qvalue\n",
    "            minginivalue=ginivalue\n",
    "    #\n",
    "    # return the best function, the value and its gini value\n",
    "    #\n",
    "    return(bestf,bestvalue,minginivalue)  \n",
    "\n",
    "\n",
    "def find_all_set_splits(value_list):\n",
    "    splits=[]\n",
    "    n=len(value_list)\n",
    "    m=int(n/2)\n",
    "    for sz in range(1,m+1):\n",
    "        combs=it.combinations(value_list,sz)\n",
    "        for comb in combs:\n",
    "            splits.append(list(comb))\n",
    "    if 2*m<n:\n",
    "        return(splits)\n",
    "    #\n",
    "    # even case - need to add in subsets of size n/2\n",
    "    #\n",
    "    combs=it.combinations(value_list,m+1)\n",
    "    svalue_list=set(value_list) # by the way - sets can't contain mutable elements!!!\n",
    "    for comb in combs:\n",
    "        s=set(comb)\n",
    "        sc=svalue_list.difference(s)\n",
    "        if s not in splits and svalue_list.difference(s):\n",
    "            splits.append(list(s))\n",
    "    return(splits)\n",
    "    \n",
    "def find_best_splitting_function_categorical_variable(data,vname,min_node_size):\n",
    "    values=list(data[vname].unique())\n",
    "    nvalues=len(values)\n",
    "    minginivalue=data.shape[0] # Gini can't be this big\n",
    "    subset_list=find_all_set_splits(values)\n",
    "    bestf=None\n",
    "    bestsubset=None\n",
    "    for subset in subset_list:\n",
    "        def f(row):\n",
    "            if row[vname] in subset:\n",
    "                return(\"left\")\n",
    "            else:\n",
    "                return(\"right\")\n",
    "        ginivalue=Gini_criterion(data,f,min_node_size)\n",
    "        if ginivalue<minginivalue:\n",
    "            bestf=f\n",
    "            bestsubset=subset\n",
    "            minginivalue=ginivalue\n",
    "    return(bestf,bestsubset,minginivalue)  \n",
    "\n",
    "def find_best_split(data,cont_vars,cat_vars,min_node_size):\n",
    "    minginivalue=data.shape[0]\n",
    "    bestf=None\n",
    "    bestvar=None\n",
    "    bestvartype=None\n",
    "    bestvalue=None\n",
    "    for catvar in cat_vars:\n",
    "        f,b,g=find_best_splitting_function_categorical_variable(data,catvar,min_node_size)\n",
    "        if g<minginivalue:\n",
    "            minginivalue=g\n",
    "            bestvar=catvar\n",
    "            bestvartype=\"categorical\"\n",
    "            bestvalue=b\n",
    "            bestf=f\n",
    "    for contvar in cont_vars:\n",
    "        f,b,g=find_best_splitting_function_continuous_variable(data,contvar,min_node_size)\n",
    "        if g<minginivalue:\n",
    "            minginivalue=g\n",
    "            bestvar=contvar\n",
    "            bestvartype=\"continuous\"\n",
    "            bestvalue=b\n",
    "            bestf=f\n",
    "    return bestf,bestvar,bestvartype,bestvalue,minginivalue\n",
    "\n",
    "class node:\n",
    "    __slots__=('parent','left_child','right_child','data')\n",
    "    #\n",
    "    # We instantiate a node by passing a parent (which can be None) \n",
    "    # and a dictionary\n",
    "    #\n",
    "    def __init__(self,parent,data):\n",
    "        if parent==None:\n",
    "            # making this a root node\n",
    "            self.data=data\n",
    "            self.data[\"depth\"]=0\n",
    "            self.parent=None\n",
    "        else:\n",
    "            # making this a non-root node\n",
    "            self.data=data\n",
    "            self.data[\"depth\"]=parent.data[\"depth\"]+1\n",
    "            self.parent=parent\n",
    "        self.left_child=None\n",
    "        self.right_child=None\n",
    "    def get_parent(self): # return the node's parent\n",
    "        return(self.parent)\n",
    "    def get_data(self):   # return the node's data\n",
    "        return(self.data)\n",
    "    def get_depth(self):  # return the node's depth\n",
    "        return(self.data[\"depth\"])\n",
    "    def get_label(self):\n",
    "        return(self.data[\"label\"])\n",
    "    def set_label(self,label):\n",
    "        self.data[\"label\"]=label\n",
    "    def get_left_child(self):\n",
    "        return(self.left_child)\n",
    "    def get_right_child(self):\n",
    "        return(self.right_child)\n",
    "    def spawn_left_child(self,data):\n",
    "        # create a new node n with self as parent w/ given data\n",
    "        n=node(parent=self,data=data)\n",
    "        #n.data=data\n",
    "        n.data[\"depth\"]=self.data[\"depth\"]+1\n",
    "        self.left_child=n\n",
    "        return(n)\n",
    "    def spawn_right_child(self,data):\n",
    "        n=node(parent=self,data=data)\n",
    "        n.data=data\n",
    "        n.data[\"depth\"]=self.data[\"depth\"]+1\n",
    "        self.right_child=n\n",
    "        return(n)\n",
    "    #\n",
    "    # string consisting of information about node\n",
    "    #\n",
    "    def __str__(self):\n",
    "        s=\"node label = \"+self.data[\"label\"]+\"\\n\"\n",
    "        if self.parent==None:\n",
    "            s+=\"   no parent i.e. root node\\n\"\n",
    "        else:\n",
    "            s+=\"   parent label = \" + self.parent.data[\"label\"]+\"\\n\"\n",
    "        if self.left_child==None:\n",
    "            s+=\"   no left child\\n\"\n",
    "        else:\n",
    "            s+=\"   left child label \" + self.left_child.data[\"label\"]+\"\\n\"\n",
    "        if self.right_child==None:\n",
    "            s+=\"   no right child\\n\"\n",
    "        else:\n",
    "            s+=\"   right child label \" + self.right_child.data[\"label\"]+\"\\n\"\n",
    "        \n",
    "        return(s)\n",
    "class node:\n",
    "    __slots__=('parent','left_child','right_child','data')\n",
    "    #\n",
    "    # We instantiate a node by passing a parent (which can be None) \n",
    "    # and a dictionary\n",
    "    #\n",
    "    def __init__(self,parent,data):\n",
    "        if parent==None:\n",
    "            # making this a root node\n",
    "            self.data=data\n",
    "            self.data[\"depth\"]=0\n",
    "            self.parent=None\n",
    "        else:\n",
    "            # making this a non-root node\n",
    "            self.data=data\n",
    "            self.data[\"depth\"]=parent.data[\"depth\"]+1\n",
    "            self.parent=parent\n",
    "        self.left_child=None\n",
    "        self.right_child=None\n",
    "    def get_parent(self): # return the node's parent\n",
    "        return(self.parent)\n",
    "    def get_data(self):   # return the node's data\n",
    "        return(self.data)\n",
    "    def get_depth(self):  # return the node's depth\n",
    "        return(self.data[\"depth\"])\n",
    "    def get_label(self):\n",
    "        return(self.data[\"label\"])\n",
    "    def set_label(self,label):\n",
    "        self.data[\"label\"]=label\n",
    "    def get_left_child(self):\n",
    "        return(self.left_child)\n",
    "    def get_right_child(self):\n",
    "        return(self.right_child)\n",
    "    def spawn_left_child(self,data):\n",
    "        # create a new node n with self as parent w/ given data\n",
    "        n=node(parent=self,data=data)\n",
    "        #n.data=data\n",
    "        n.data[\"depth\"]=self.data[\"depth\"]+1\n",
    "        self.left_child=n\n",
    "        return(n)\n",
    "    def spawn_right_child(self,data):\n",
    "        n=node(parent=self,data=data)\n",
    "        n.data=data\n",
    "        n.data[\"depth\"]=self.data[\"depth\"]+1\n",
    "        self.right_child=n\n",
    "        return(n)\n",
    "    #\n",
    "    # string consisting of information about node\n",
    "    #\n",
    "    def __str__(self):\n",
    "        s=\"node label = \"+self.data[\"label\"]+\"\\n\"\n",
    "        if self.parent==None:\n",
    "            s+=\"   no parent i.e. root node\\n\"\n",
    "        else:\n",
    "            s+=\"   parent label = \" + self.parent.data[\"label\"]+\"\\n\"\n",
    "        if self.left_child==None:\n",
    "            s+=\"   no left child\\n\"\n",
    "        else:\n",
    "            s+=\"   left child label \" + self.left_child.data[\"label\"]+\"\\n\"\n",
    "        if self.right_child==None:\n",
    "            s+=\"   no right child\\n\"\n",
    "        else:\n",
    "            s+=\"   right child label \" + self.right_child.data[\"label\"]+\"\\n\"\n",
    "        return(s)\n",
    "    def treestr(self):\n",
    "        d=self.data\n",
    "        depth=d[\"depth\"]\n",
    "        G=d[\"gini\"]\n",
    "        Gstring=\"G: {:8.2f} \".format(G)\n",
    "        Y0=d[\"Ycts\"][0]\n",
    "        Y1=d[\"Ycts\"][1]\n",
    "        Ycts_string=\"N: \"+str(Y0+Y1)+\" N0: \"+str(Y0)+\" \"+\" N1:\"+str(Y1)+\"\\n\"\n",
    "        p0=Y0/(Y0+Y1)\n",
    "        p1=Y1/(Y0+Y1)\n",
    "        pstring=\"p0: {:5.4f} p1: {:5.4f}\\n\".format(p0,p1)\n",
    "        spaces=\"\".join([\"  \" for i in range(depth)])\n",
    "        s=spaces+d[\"label\"]+\"\\n\"\n",
    "        s+=spaces+Gstring+Ycts_string\n",
    "        s+=spaces+pstring\n",
    "        #\n",
    "        # if this node has a split, include info about it\n",
    "        #\n",
    "        if \"splitinfo\" in self.data:\n",
    "            splitinfo=self.data[\"splitinfo\"]\n",
    "        \n",
    "        \n",
    "        \n",
    "        if self.left_child!=None:\n",
    "            s+=self.left_child.treestr()\n",
    "            s+=self.right_child.treestr()\n",
    "        return(s)\n",
    "    def treeprint(self):\n",
    "        s=self.treestr()\n",
    "        print(s)\n",
    "    def build_tree(self,contvars,catvars,min_node_size):  \n",
    "        cdf=self.data[\"df\"]\n",
    "    \n",
    "        # compute Y counts in this node and store them\n",
    "        N0=np.sum(1-cdf[\"Y\"])\n",
    "        N1=np.sum(cdf[\"Y\"])\n",
    "        self.data[\"Ycts\"]=[N0,N1]\n",
    "    \n",
    "        #\n",
    "        # Gini for a node is N*p(1-p) where p is prop of 1's\n",
    "        # so this equalis (N0+N1)*(N0/(N0+N1)))*(N1/(N0+N1)) = N0*N1/(N0+N1)\n",
    "        #\n",
    "        self.data[\"gini\"]=N0*N1/(N0+N1)\n",
    "    \n",
    "        if self.data[\"df\"].shape[0]>=min_node_size:\n",
    "            print(\"new node to try splitting: \"+self.data[\"label\"]+\" size= \"+str(self.data[\"df\"].shape[0]))\n",
    "        \n",
    "            # find best split\n",
    "            f,v,vtype,value,g=find_best_split(self.data[\"df\"],contvars,catvars,min_node_size)\n",
    "        \n",
    "            #\n",
    "            # if the split leads to a bigger gini, we don't split the node\n",
    "            # so compare to gini at current node\n",
    "            #\n",
    "            if g>=self.data[\"gini\"]:\n",
    "                print(\"node is not split since gini not reduced\")\n",
    "            else:\n",
    "            \n",
    "                # determine which rows of current data frame go left and which go right\n",
    "                child_assignment=self.data[\"df\"].apply(f,axis=1)\n",
    "        \n",
    "                # compute counts of child nodes if we split\n",
    "                nleft=np.sum(child_assignment==\"left\")\n",
    "                nright=np.sum(child_assignment==\"right\")\n",
    "            \n",
    "                if nleft<min_node_size or nright<min_node_size:\n",
    "                    print(\"node is not split because of minimum node size constraint\")\n",
    "                \n",
    "                else:\n",
    "                \n",
    "                    # attach splitting function to data at this node\n",
    "                    splitinfo={\"f\":f, \"vname\": v, \"vtype\":vtype, \"value\":value}\n",
    "                    self.data[\"splitinfo\"]=splitinfo\n",
    "                     \n",
    "                    print(\"splitting node into sizes \"+str(nleft)+\" \"+str(nright))\n",
    "                    # compute data frames to put at child nodes\n",
    "                    dfleft=self.data[\"df\"].loc[child_assignment==\"left\"].copy()\n",
    "                    dfright=self.data[\"df\"].loc[child_assignment==\"right\"].copy()\n",
    "       \n",
    "                    # replace data frame indices by range\n",
    "                    dfleft.index=range(dfleft.shape[0])\n",
    "                    dfright.index=range(dfright.shape[0])\n",
    "    \n",
    "                    # create a label \n",
    "                    dataleft={\"df\":dfleft,\"label\":self.data[\"label\"]+\"L\"}\n",
    "                    dataright={\"df\":dfright,\"label\":self.data[\"label\"]+\"R\"}\n",
    "                        \n",
    "                    # create child nodes \n",
    "                    left_child=self.spawn_left_child(dataleft)\n",
    "                    right_child=self.spawn_right_child(dataright)\n",
    "               \n",
    "            \n",
    "                    # split child nodes\n",
    "                    left_child.build_tree(contvars,catvars,min_node_size)\n",
    "                    right_child.build_tree(contvars,catvars,min_node_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the method**\n",
    "\n",
    "We create a root node, attach a data frame to it, call the build_tree method a this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdata=pd.read_csv(\"mortgage_data.csv\")\n",
    "#\n",
    "# Create a Y variable - Y=1 for default Y=0 for non-default\n",
    "#\n",
    "def f(row):\n",
    "    if row[\"result\"]==\"default\":\n",
    "        return(1)\n",
    "    else:\n",
    "        return(0)\n",
    "mdata[\"Y\"]=mdata.apply(f,axis=1)\n",
    "rootnode=node(None,{\"df\":mdata,\"label\":\"\"})\n",
    "rootnode.build_tree([\"irate\",\"cscore\",\"princ\"],[\"location\"],500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootnode.treeprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classify an observation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to classify an observation, which is another recursive function.\n",
    "\n",
    "This is left as an exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
